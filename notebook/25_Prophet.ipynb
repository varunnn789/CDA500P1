{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500P1\\CDA500P1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from prophet import Prophet\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from src.config import TRANSFORMED_DATA_DIR\n",
    "from src.data_utils import split_time_series_data\n",
    "from src.experiment_utils import set_mlflow_tracking, log_model_to_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series_by_cutoff_date(\n",
    "    df: pd.DataFrame,\n",
    "    target_column: str,\n",
    "    cutoff_date: str\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits a time series DataFrame into training and testing sets based on a cutoff date.\n",
    "    Retains only 'pickup_hour' and the target column, and aggregates by 'pickup_hour'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the time series data.\n",
    "        target_column (str): The name of the target column to separate from the features.\n",
    "        cutoff_date (str): The cutoff date for splitting the data (e.g., \"2023-08-01\").\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "            - train_data (pd.DataFrame): Training data up to the cutoff date.\n",
    "            - test_data (pd.DataFrame): Testing data after the cutoff date.\n",
    "    \"\"\"\n",
    "    # Keep only 'pickup_hour' and target column\n",
    "    df = df[[\"pickup_hour\", target_column]]\n",
    "\n",
    "    # Convert 'pickup_hour' to datetime if not already\n",
    "    df[\"pickup_hour\"] = pd.to_datetime(df[\"pickup_hour\"])\n",
    "\n",
    "    # Aggregate data by 'pickup_hour'\n",
    "    df_aggregated = df.groupby(\"pickup_hour\")[target_column].sum().reset_index()\n",
    "\n",
    "    # Sort the DataFrame by date\n",
    "    df_sorted = df_aggregated.sort_values(\"pickup_hour\")\n",
    "\n",
    "    # Split data into training and testing sets based on cutoff date\n",
    "    train_data = df_sorted[df_sorted[\"pickup_hour\"] <= pd.Timestamp(cutoff_date)].reset_index(drop=True)\n",
    "    test_data = df_sorted[df_sorted[\"pickup_hour\"] > pd.Timestamp(cutoff_date)].reset_index(drop=True)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for Prophet\n",
    "def prepare_prophet_data(df: pd.DataFrame, target_column: str) -> pd.DataFrame:\n",
    "    df_prepared = df.rename(columns={\"pickup_hour\": \"ds\", target_column: \"y\"})\n",
    "    df_prepared[\"ds\"] = pd.to_datetime(df_prepared[\"ds\"])  # Ensure datetime format\n",
    "    return df_prepared\n",
    "\n",
    "# Fit and forecast using Prophet\n",
    "def fit_and_forecast_prophet(train_data: pd.DataFrame, test_data: pd.DataFrame) -> tuple:\n",
    "    model = Prophet()\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # Calculate how many periods we need to extend to match test data\n",
    "    last_train_date = train_data[\"ds\"].max()\n",
    "    last_test_date = test_data[\"ds\"].max()\n",
    "    periods_needed = (last_test_date - last_train_date).days * 24  # Assuming hourly frequency\n",
    "\n",
    "    future = model.make_future_dataframe(periods=periods_needed, freq=\"H\")  # Extend forecast\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    return model, forecast\n",
    "\n",
    "def evaluate_prophet(test_data: pd.Series, forecast: pd.DataFrame) -> float:\n",
    "    forecast_filtered = forecast[forecast[\"ds\"].isin(test_data.index)]\n",
    "\n",
    "    if forecast_filtered.empty:\n",
    "        raise ValueError(f\"No overlap! Check formats:\\n\"\n",
    "                         f\"Test Data Range: {test_data.index.min()} to {test_data.index.max()}\\n\"\n",
    "                         f\"Forecast Range: {forecast['ds'].min()} to {forecast['ds'].max()}\")\n",
    "\n",
    "    mae = mean_absolute_error(test_data.values, forecast_filtered[\"yhat\"].values)\n",
    "    print(f\"Test Set MAE: {mae:.2f}\")\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rides_t-672</th>\n",
       "      <th>rides_t-671</th>\n",
       "      <th>rides_t-670</th>\n",
       "      <th>rides_t-669</th>\n",
       "      <th>rides_t-668</th>\n",
       "      <th>rides_t-667</th>\n",
       "      <th>rides_t-666</th>\n",
       "      <th>rides_t-665</th>\n",
       "      <th>rides_t-664</th>\n",
       "      <th>rides_t-663</th>\n",
       "      <th>...</th>\n",
       "      <th>rides_t-7</th>\n",
       "      <th>rides_t-6</th>\n",
       "      <th>rides_t-5</th>\n",
       "      <th>rides_t-4</th>\n",
       "      <th>rides_t-3</th>\n",
       "      <th>rides_t-2</th>\n",
       "      <th>rides_t-1</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87615</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>133</td>\n",
       "      <td>126</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>263</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87616</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>123</td>\n",
       "      <td>136</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>263</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87617</th>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>116</td>\n",
       "      <td>137</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>263</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87618</th>\n",
       "      <td>117</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>69</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>263</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87619</th>\n",
       "      <td>120</td>\n",
       "      <td>82</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>95</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>61</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>263</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87620 rows × 675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
       "0                0            0            0            0            0   \n",
       "1                0            0            0            0            0   \n",
       "2                0            0            0            0            0   \n",
       "3                0            0            0            0            0   \n",
       "4                0            0            0            0            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "87615           25           14            5            3            7   \n",
       "87616           30            7            9            6            5   \n",
       "87617           50           26           17            9            8   \n",
       "87618          117           88           39           19           14   \n",
       "87619          120           82           61           41           13   \n",
       "\n",
       "       rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
       "0                0            0            0            0            0  ...   \n",
       "1                0            0            0            0            0  ...   \n",
       "2                0            0            0            0            0  ...   \n",
       "3                0            0            0            0            0  ...   \n",
       "4                0            0            0            0            0  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "87615           16           53          133          126          136  ...   \n",
       "87616           23           58          123          136          108  ...   \n",
       "87617           11           43          116          137          132  ...   \n",
       "87618           12           27           37           70           97  ...   \n",
       "87619           12           26           37           45           99  ...   \n",
       "\n",
       "       rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  rides_t-2  \\\n",
       "0              1          0          0          0          0          0   \n",
       "1              0          0          0          0          0          0   \n",
       "2              0          0          0          0          0          0   \n",
       "3              0          0          0          0          0          0   \n",
       "4              0          0          0          0          0          0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "87615         62         62         58         50         48         42   \n",
       "87616         64         79         65         71         72         75   \n",
       "87617         81         78         60         85         63         62   \n",
       "87618         84         75        100         98         88         77   \n",
       "87619         85         76         95         68         76         71   \n",
       "\n",
       "       rides_t-1  pickup_hour  pickup_location_id  target  \n",
       "0              0   2023-01-29                   2       0  \n",
       "1              0   2023-01-30                   2       0  \n",
       "2              0   2023-01-31                   2       0  \n",
       "3              0   2023-02-01                   2       0  \n",
       "4              0   2023-02-02                   2       0  \n",
       "...          ...          ...                 ...     ...  \n",
       "87615         37   2023-12-27                 263      12  \n",
       "87616         35   2023-12-28                 263      19  \n",
       "87617         37   2023-12-29                 263      38  \n",
       "87618         69   2023-12-30                 263      59  \n",
       "87619         61   2023-12-31                 263      65  \n",
       "\n",
       "[87620 rows x 675 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(87620, 675)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_58696\\1428783236.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"pickup_hour\"] = pd.to_datetime(df[\"pickup_hour\"])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(TRANSFORMED_DATA_DIR / \"tabular_data.parquet\")\n",
    "df\n",
    "df.shape\n",
    "cutoff_date = \"2023-08-01\"\n",
    "train_data, test_data = split_time_series_by_cutoff_date(df, target_column=\"target\", cutoff_date=cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "# y_train\n",
    "# X_val\n",
    "# y_val\n",
    "# X_test\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare training and test data for Prophet\n",
    "# train_data = prepare_prophet_data(X_train.join(y_train), target_column=\"target\")\n",
    "# test_data = prepare_prophet_data(X_test.join(y_test), target_column=\"target\")\n",
    "# train_data\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:cmd: where.exe tbb.dll\n",
      "cwd: None\n",
      "DEBUG:cmdstanpy:Adding TBB (c:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500P1\\CDA500P1\\Lib\\site-packages\\prophet\\stan_model\\cmdstan-2.33.1\\stan\\lib\\stan_math\\lib\\tbb) to PATH\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: C:\\Users\\singh\\AppData\\Local\\Temp\\tmpiuqd6khn\\mxe5t4vt.json\n",
      "DEBUG:cmdstanpy:input tempfile: C:\\Users\\singh\\AppData\\Local\\Temp\\tmpiuqd6khn\\c05wqs6y.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['C:\\\\Users\\\\singh\\\\Downloads\\\\CDS500_Applied_ML_DS\\\\Projects\\\\CDA500P1\\\\CDA500P1\\\\Lib\\\\site-packages\\\\prophet\\\\stan_model\\\\prophet_model.bin', 'random', 'seed=24648', 'data', 'file=C:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Temp\\\\tmpiuqd6khn\\\\mxe5t4vt.json', 'init=C:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Temp\\\\tmpiuqd6khn\\\\c05wqs6y.json', 'output', 'file=C:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Temp\\\\tmpiuqd6khn\\\\prophet_model2b20375i\\\\prophet_model-20250305145158.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "14:51:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "14:51:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Range: 2023-08-02 00:00:00 to 2023-12-31 00:00:00\n",
      "Forecast Range: 2023-01-29 00:00:00 to 2023-12-31 00:00:00\n",
      "                      ds         yhat\n",
      "3823 2023-12-30 15:00:00  5525.859313\n",
      "3824 2023-12-30 16:00:00  5498.256195\n",
      "3825 2023-12-30 17:00:00  5459.426492\n",
      "3826 2023-12-30 18:00:00  5409.322440\n",
      "3827 2023-12-30 19:00:00  5347.978588\n",
      "3828 2023-12-30 20:00:00  5275.512907\n",
      "3829 2023-12-30 21:00:00  5192.127083\n",
      "3830 2023-12-30 22:00:00  5098.105955\n",
      "3831 2023-12-30 23:00:00  4993.816118\n",
      "3832 2023-12-31 00:00:00  4879.703690\n",
      "            ds     y\n",
      "142 2023-12-22  3407\n",
      "143 2023-12-23  2867\n",
      "144 2023-12-24  1977\n",
      "145 2023-12-25  1525\n",
      "146 2023-12-26   834\n",
      "147 2023-12-27  1414\n",
      "148 2023-12-28  1599\n",
      "149 2023-12-29  2276\n",
      "150 2023-12-30  3190\n",
      "151 2023-12-31  3407\n"
     ]
    }
   ],
   "source": [
    "target_column=\"target\"\n",
    "train_data_prepared = prepare_prophet_data(train_data, target_column)\n",
    "test_data_prepared = prepare_prophet_data(test_data, target_column)\n",
    "model, forecast = fit_and_forecast_prophet(train_data_prepared, test_data_prepared)\n",
    "print(f\"Test Data Range: {test_data_prepared['ds'].min()} to {test_data_prepared['ds'].max()}\")\n",
    "print(f\"Forecast Range: {forecast['ds'].min()} to {forecast['ds'].max()}\")\n",
    "print(forecast[['ds', 'yhat']].tail(10)) # See last few timestamps\n",
    "print(test_data_prepared.tail(10))  # See last few test timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Range: 2023-08-02 00:00:00 to 2023-12-31 00:00:00\n",
      "Forecast Range: 2023-01-29 00:00:00 to 2023-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Data Range:\", test_data_prepared[\"ds\"].min(), \"to\", test_data_prepared[\"ds\"].max())\n",
    "print(\"Forecast Range:\", forecast[\"ds\"].min(), \"to\", forecast[\"ds\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds         yhat\n",
      "208 2023-08-02  1842.184486\n",
      "232 2023-08-03  2229.211516\n",
      "256 2023-08-04  3218.555235\n",
      "280 2023-08-05  5134.523728\n",
      "304 2023-08-06  5178.258211\n",
      "          ds     y\n",
      "0 2023-08-02  2028\n",
      "1 2023-08-03  2321\n",
      "2 2023-08-04  3027\n",
      "3 2023-08-05  4877\n",
      "4 2023-08-06  4632\n"
     ]
    }
   ],
   "source": [
    "forecast[\"ds\"] = pd.to_datetime(forecast[\"ds\"])\n",
    "test_data_prepared[\"ds\"] = pd.to_datetime(test_data_prepared[\"ds\"])\n",
    "\n",
    "# Filter forecast to contain only test set dates\n",
    "forecast_filtered = forecast[forecast[\"ds\"].isin(test_data_prepared[\"ds\"])]\n",
    "\n",
    "# Check alignment\n",
    "print(forecast_filtered[[\"ds\", \"yhat\"]].head())\n",
    "print(test_data_prepared[[\"ds\", \"y\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prepared = test_data_prepared.sort_values(\"ds\").set_index(\"ds\")\n",
    "forecast_filtered = forecast_filtered.sort_values(\"ds\").set_index(\"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data (y): [2028 2321 3027 4877 4632 1515 1342 1538 1886 2499]\n",
      "Predicted (yhat): [1842.18448623 2229.21151575 3218.55523515 5134.52372761 5178.25821122\n",
      " 1516.82023139 1352.60652376 1827.96760425 2214.99463377 3204.33835318]\n",
      "Test Data Size: 152\n",
      "Forecast Data Size: 152\n",
      "Test Set MAE Per Day: 671.03\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compare test values and forecasted values\n",
    "print(\"Test Data (y):\", test_data_prepared[\"y\"].values[:10])\n",
    "print(\"Predicted (yhat):\", forecast_filtered[\"yhat\"].values[:10])\n",
    "\n",
    "# Ensure lengths match\n",
    "print(\"Test Data Size:\", len(test_data_prepared))\n",
    "print(\"Forecast Data Size:\", len(forecast_filtered))\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(test_data_prepared[\"y\"].values, forecast_filtered[\"yhat\"].values)\n",
    "print(f\"Test Set MAE Per Day: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set MAE Per Hour: 27.96\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Set MAE Per Hour: {mae/24:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cmdstanpy:cmd: where.exe tbb.dll\n",
      "cwd: None\n",
      "DEBUG:cmdstanpy:TBB already found in load path\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: C:\\Users\\singh\\AppData\\Local\\Temp\\tmpiuqd6khn\\3tf7p92g.json\n",
      "DEBUG:cmdstanpy:input tempfile: C:\\Users\\singh\\AppData\\Local\\Temp\\tmpiuqd6khn\\pheftpyz.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['C:\\\\Users\\\\singh\\\\Downloads\\\\CDS500_Applied_ML_DS\\\\Projects\\\\CDA500P1\\\\CDA500P1\\\\Lib\\\\site-packages\\\\prophet\\\\stan_model\\\\prophet_model.bin', 'random', 'seed=23008', 'data', 'file=C:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Temp\\\\tmpiuqd6khn\\\\3tf7p92g.json', 'init=C:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Temp\\\\tmpiuqd6khn\\\\pheftpyz.json', 'output', 'file=C:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Temp\\\\tmpiuqd6khn\\\\prophet_model8h9ump5u\\\\prophet_model-20250305145836.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "14:58:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "14:58:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set MAE: 18.21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.214036831083476"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Prepare data for Prophet\n",
    "def prepare_data_for_prophet(df):\n",
    "    df_prophet = pd.DataFrame()\n",
    "    df_prophet['ds'] = df['pickup_hour']\n",
    "    df_prophet['y'] = df['target']  # Using the most recent ride data as the target\n",
    "    return df_prophet\n",
    "\n",
    "# Step 2: Create and fit Prophet model\n",
    "def fit_prophet_model(df_prophet):\n",
    "    model = Prophet()\n",
    "    model.fit(df_prophet)\n",
    "    return model\n",
    "\n",
    "# Step 3: Make predictions\n",
    "def make_predictions(model, periods=30):\n",
    "    future_dates = model.make_future_dataframe(periods=periods)\n",
    "    forecast = model.predict(future_dates)\n",
    "    return forecast\n",
    "\n",
    "# Step 4: Visualize results\n",
    "def visualize_results(model, forecast):\n",
    "    fig1 = model.plot(forecast)\n",
    "    fig2 = model.plot_components(forecast)\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: Evaluate model performance (calculate MAE based on forecast overlap)\n",
    "def evaluate_model(df_test, forecast):\n",
    "    # Merge the test data with the forecast for overlap\n",
    "    forecast_filtered = forecast[forecast['ds'].isin(df_test['ds'])]\n",
    "    \n",
    "    if forecast_filtered.empty:\n",
    "        raise ValueError(f\"No overlap! Check formats:\\n\"\n",
    "                         f\"Test Data Range: {df_test['ds'].min()} to {df_test['ds'].max()}\\n\"\n",
    "                         f\"Forecast Range: {forecast['ds'].min()} to {forecast['ds'].max()}\")\n",
    "    \n",
    "    # Ensure proper alignment between forecast and test data by resetting indices\n",
    "    forecast_filtered = forecast_filtered.set_index('ds').sort_index()\n",
    "    df_test = df_test.set_index('ds').sort_index()\n",
    "\n",
    "    # Now calculate Mean Absolute Error (MAE)\n",
    "    forecast_filtered = forecast_filtered.loc[df_test.index]\n",
    "    \n",
    "    # Check if both dataframes have the same length and index after filtering\n",
    "    if len(forecast_filtered) != len(df_test):\n",
    "        raise ValueError(f\"Data length mismatch! Forecast: {len(forecast_filtered)}, Test: {len(df_test)}\")\n",
    "    \n",
    "    mae = np.mean(np.abs(forecast_filtered['yhat'].values - df_test['y'].values))\n",
    "    \n",
    "    print(f\"Test Set MAE: {mae:.2f}\")\n",
    "    return mae\n",
    "\n",
    "# Prepare data for Prophet\n",
    "df_prophet = prepare_data_for_prophet(df)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(len(df_prophet) * 0.8)\n",
    "df_train = df_prophet[:train_size]\n",
    "df_test = df_prophet[train_size:]\n",
    "\n",
    "# Fit model on training data\n",
    "model = fit_prophet_model(df_train)\n",
    "\n",
    "# Make predictions\n",
    "forecast = make_predictions(model, periods=len(df_test))\n",
    "\n",
    "# Evaluate model performance (calculate MAE)\n",
    "evaluate_model(df_test, forecast)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDA500P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
